<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Random Forest on The Hungry Wonderer</title>
    <link>/tags/random-forest/</link>
    <description>Recent content in Random Forest on The Hungry Wonderer</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en-uk</language>
    <lastBuildDate>Tue, 04 Oct 2016 00:00:00 +0000</lastBuildDate>
    
	<atom:link href="/tags/random-forest/index.xml" rel="self" type="application/rss+xml" />
    
    
    <item>
      <title>On Variable Importance with Random Forests</title>
      <link>/posts/2016-10-04-on-variable-importance-with-rf/</link>
      <pubDate>Tue, 04 Oct 2016 00:00:00 +0000</pubDate>
      
      <guid>/posts/2016-10-04-on-variable-importance-with-rf/</guid>
      <description>IntroductionOne of the big challenges in predictive modelling is determining which variables to use as predictors. This challenge becomes particularly difficult when the number of possible predictors becomes very large, making manual exploratory methods or the more “traditional” forward/backward stepwise regression models impractical, particularly when interactions between variables need to be considered.
One very practical and useful by-product of the random forest algorithm (and gradient boosting machines) is the variable importance which can be calculated as part of the model fitting process.</description>
    </item>
    
  </channel>
</rss>